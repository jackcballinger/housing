{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BR1\n",
      "142 results found\n",
      "obtaining soup...\n",
      "soup formatted\n",
      "json retrieved\n",
      "json formatted\n",
      "BR1 complete\n",
      "\n",
      "\n",
      "\n",
      "BR2\n",
      "140 results found\n",
      "obtaining soup...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-346fcea19131>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistrict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[0mhousing_soup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_soup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdistrict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m     \u001b[0mhousing_soup_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat_data_soup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhousing_soup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdistrict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m     \u001b[0mhousing_json\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdistrict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[0mhousing_json_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat_data_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhousing_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-95-346fcea19131>\u001b[0m in \u001b[0;36mformat_data_soup\u001b[1;34m(soup, region)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0madded_reduced_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mletting_agent_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mletting_agent_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_pictures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_soup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[0mmain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'main'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0msearch_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'l-searchResults'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-95-346fcea19131>\u001b[0m in \u001b[0;36mget_soup\u001b[1;34m(index, region)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mParserRejectedMarkup\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m_feed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m         \u001b[1;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\bs4\\builder\\_htmlparser.py\u001b[0m in \u001b[0;36mfeed\u001b[1;34m(self, markup)\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m             \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mHTMLParseError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m             warnings.warn(RuntimeWarning(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\html\\parser.py\u001b[0m in \u001b[0;36mfeed\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    109\u001b[0m         \"\"\"\n\u001b[0;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgoahead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\html\\parser.py\u001b[0m in \u001b[0;36mgoahead\u001b[1;34m(self, end)\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mstarttagopen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# < + letter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m                     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_starttag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"</\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m                     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_endtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\html\\parser.py\u001b[0m in \u001b[0;36mparse_starttag\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_startendtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_starttag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCDATA_CONTENT_ELEMENTS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_cdata_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\bs4\\builder\\_htmlparser.py\u001b[0m in \u001b[0;36mhandle_starttag\u001b[1;34m(self, name, attrs, handle_empty_element)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mattrvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\"\"'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;31m#print \"START\", name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[0mtag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_starttag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_empty_element\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhandle_empty_element\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[1;31m# Unlike other parsers, html.parser doesn't send separate end tag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36mhandle_starttag\u001b[1;34m(self, name, namespace, nsprefix, attrs)\u001b[0m\n\u001b[0;32m    466\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_most_recent_element\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_most_recent_element\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_element\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_most_recent_element\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def import_district_file(file_location):\n",
    "    district_df = pd.read_csv(file_location)\n",
    "    return district_df\n",
    "\n",
    "def get_district_dict():\n",
    "    district_df = import_district_file('C:/Users/ballinj/housing/london_district_codes.csv')\n",
    "    district_dict = dict(zip(list(district_df['district']), list(district_df['code'])))\n",
    "    return district_dict\n",
    "\n",
    "def get_borough_dict():\n",
    "    df = pd.read_csv('london_borough_list.csv')\n",
    "    borough_dict = dict(zip(list(df['borough']),list(df['code'])))\n",
    "    return borough_dict\n",
    "\n",
    "def get_no_results(soup):\n",
    "    no_results = soup.find('span', attrs={'class':'searchHeader-resultCount'}).text.strip()\n",
    "    return no_results\n",
    "\n",
    "def get_soup(index, region):\n",
    "    district_id = district_dict[region]\n",
    "    cert = \"C:/Users/ballinj/housing/ca-certificates.crt\"\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1667.0 Safari/537.36'}\n",
    "    url = 'https://www.rightmove.co.uk/property-for-sale/find.html'\n",
    "    params = {'minBedrooms':2,\n",
    "              'propertyTypes':'detached%2Cflat%2Csemi-detached%2Cterraced',\n",
    "              'keywords':'',                  \n",
    "              'dontShow':'retirement%2CsharedOwnership',\n",
    "              'channel':'BUY',\n",
    "              'secondaryDisplayPropertyType':'housesandflats',\n",
    "              'index': str(index), \n",
    "              'retirement':'false',\n",
    "              'includeSSTC':'false',\n",
    "              'partBuyPartRent':'false',\n",
    "              'sortType':2,\n",
    "              'minPrice':200000,\n",
    "              'viewType':'list',\n",
    "              'maxPrice':450000,\n",
    "              'radius':0.0,\n",
    "              'locationIdentifier':'OUTCODE%' + str(district_id)[str(district_id).find('%')+1:]}\n",
    "    params_string = \"&\".join(\"%s=%s\" % (k,v) for k,v in params.items())\n",
    "    r = requests.get(url, params=params_string)\n",
    "    c = r.content    \n",
    "    soup = BeautifulSoup(c, 'html.parser') \n",
    "    return soup\n",
    "\n",
    "def get_json(index, region):\n",
    "    district_id = district_dict[region]\n",
    "    cert = \"C:/Users/ballinj/housing/ca-certificates.crt\"\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1667.0 Safari/537.36'}\n",
    "    url = 'https://www.rightmove.co.uk/property-for-sale/map.html'\n",
    "    params = {'minBedrooms':2,\n",
    "              'propertyTypes':'detached%2Cflat%2Csemi-detached%2Cterraced',\n",
    "              'keywords':'',                  \n",
    "              'dontShow':'retirement%2CsharedOwnership',\n",
    "              'channel':'BUY',\n",
    "              'secondaryDisplayPropertyType':'housesandflats',\n",
    "              'index': str(index), \n",
    "              'retirement':'false',\n",
    "              'includeSSTC':'false',\n",
    "              'partBuyPartRent':'false',\n",
    "              'sortType':2,\n",
    "              'minPrice':200000,\n",
    "              'viewType':'map',\n",
    "              'maxPrice':450000,\n",
    "              'radius':0.0,\n",
    "              'locationIdentifier':'OUTCODE%' + str(district_id)[str(district_id).find('%')+1:]}\n",
    "    params_string = \"&\".join(\"%s=%s\" % (k,v) for k,v in params.items())\n",
    "    r = requests.get(url, params=params_string)\n",
    "    c = r.content\n",
    "    soup = BeautifulSoup(c, 'html.parser')\n",
    "    scripts = soup.findAll('script')\n",
    "    script_list = [script if 'window.jsonModel' in str(script) else '' for script in scripts]\n",
    "    script_list = [script for script in script_list if script != '']\n",
    "    script = str(script_list[0])\n",
    "    script = script[script.find('{'):script.rfind('}')+1]\n",
    "    properties_json = json.loads(script)\n",
    "    print('json retrieved')\n",
    "    return properties_json\n",
    "\n",
    "def format_data_soup(soup, region):\n",
    "    no_results = get_no_results(soup)\n",
    "    print(no_results + ' results found')\n",
    "    print('obtaining soup...')\n",
    "    index_array = np.arange(0,int(no_results)+24,24).tolist()\n",
    "    listing_ids, links, property_types, addresses, prices, prices_per_week, featured_properties = [],[],[],[],[],[],[]\n",
    "    added_reduced_array, letting_agent_name, letting_agent_number, num_pictures = [],[],[],[]\n",
    "    for index in index_array:\n",
    "        soup = get_soup(index, region)\n",
    "        main_data = soup.find('div', attrs={'class':'main'})\n",
    "        search_results = soup.find('div', attrs={'class':'l-searchResults'})\n",
    "        ids = search_results.findAll('a', attrs={'class':'propertyCard-anchor'})#['id']\n",
    "        for id in ids:\n",
    "            listing_ids.append(id['id'][4:])\n",
    "        listing_data = search_results.findAll('div', attrs={'class':'propertyCard-wrapper'})\n",
    "        for listing in listing_data:\n",
    "            featured_properties.append(listing.find('div', attrs={'class':'propertyCard-moreInfoFeaturedTitle'}).text.strip())\n",
    "\n",
    "            details = listing.find('div', attrs={'class':'propertyCard-details'})\n",
    "            addresses.append(listing.find('address').text.strip())\n",
    "            property_types.append(listing.find('h2').text.strip())\n",
    "            links.append('https://www.rightmove.co.uk/' + details.find('a')['href'])\n",
    "\n",
    "            pricing = listing.find('div', attrs={'class':'propertyCard-price'})\n",
    "            prices.append(pricing.find('div', attrs={'class':'propertyCard-priceValue'}).text.strip())\n",
    "            added_reduced_array.append(listing.find('div', attrs={'class':'propertyCard-branchSummary'}).find('span', attrs={'class':'propertyCard-branchSummary-addedOrReduced'}).text.strip())\n",
    "            estate_agent = listing.find('div', attrs={'class':'propertyCard-branchSummary'}).find('span', attrs={'class':'propertyCard-branchSummary-branchName'}).text.strip()\n",
    "            estate_agent = estate_agent[estate_agent.find('by')+3:].strip()\n",
    "            letting_agent_name.append(estate_agent)\n",
    "            letting_agent_number.append(listing.find('div', attrs={'class':'propertyCard-contacts'}).find('a', attrs={'class':'propertyCard-contactsPhoneNumber'}).text.strip())\n",
    "            meta_data = listing.find('div', attrs={'class':'propertyCard-moreInfoMeta'})\n",
    "            num_pictures.append(meta_data.find('span', attrs={'class':'propertyCard-moreInfoNumber'}).text.strip())\n",
    "        time.sleep(2)\n",
    "    listing_df = pd.DataFrame(listing_ids, columns=['listing_id'])\n",
    "    listing_df['address'] = addresses\n",
    "    listing_df['property_type'] = property_types\n",
    "    listing_df['property_link'] = links\n",
    "    listing_df['price'] = prices\n",
    "    listing_df['added/reduced_date'] = added_reduced_array\n",
    "    listing_df['agent_name'] = letting_agent_name\n",
    "    listing_df['agent_number'] = letting_agent_number\n",
    "    listing_df['no_pictures'] = num_pictures\n",
    "    listing_df['featured_property'] = featured_properties\n",
    "    listing_df = listing_df[~listing_df['property_type'].str.contains('share')]\n",
    "    listing_df = listing_df[~listing_df['property_type'].str.contains('Parking')]\n",
    "    listing_df = listing_df[listing_df['address']!=\"\"]\n",
    "    listing_df = listing_df[listing_df['featured_property']==\"\"]\n",
    "    listing_df = listing_df.reset_index(drop=True)\n",
    "    print('soup formatted')\n",
    "    return listing_df\n",
    "\n",
    "def format_data_json(properties_json):\n",
    "    property_id, coordinates = [],[]\n",
    "    for row in properties_json['properties']:\n",
    "        property_id.append(str(row['id']))\n",
    "        coordinates.append([row['location']['latitude'], row['location']['longitude']])\n",
    "    coordinates_dict = dict(zip(property_id, coordinates))\n",
    "    print('json formatted')\n",
    "    return coordinates_dict\n",
    "\n",
    "def housing_data_merge(housing_soup_data, housing_json_data):\n",
    "    latitudes, longitudes = [],[]\n",
    "    for id in list(housing_soup_data['listing_id']):\n",
    "        latitudes.append(housing_json_data[str(id)][0])\n",
    "        longitudes.append(housing_json_data[str(id)][1])\n",
    "    housing_soup_data['latitude'] = latitudes\n",
    "    housing_soup_data['longitude'] = longitudes\n",
    "    return housing_soup_data\n",
    "\n",
    "district_dict = get_district_dict()\n",
    "\n",
    "district_list = import_district_file('C:/Users/ballinj/housing/london_district_codes.csv')['district'].tolist()\n",
    "district_list.remove('CR0')\n",
    "housing_data_total = pd.DataFrame()\n",
    "for district in district_list:\n",
    "    print(district)\n",
    "    housing_soup = get_soup(index=0, region=district)\n",
    "    housing_soup_data = format_data_soup(housing_soup, region=district)\n",
    "    housing_json = get_json(index=0, region=district)\n",
    "    housing_json_data = format_data_json(housing_json)\n",
    "    housing_data_merge_df = housing_data_merge(housing_soup_data, housing_json_data)\n",
    "    housing_data_merge_df['district'] = district\n",
    "    housing_data_total = pd.concat([housing_data_total,housing_data_merge_df], ignore_index=True)\n",
    "    time.sleep(5)\n",
    "    print(district + ' complete')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
