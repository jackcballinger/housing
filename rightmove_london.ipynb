{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import glob\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from matplotlib import pyplot as plt\n",
    "from math import radians, cos, sin, asin, sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functions loaded\n"
     ]
    }
   ],
   "source": [
    "today = datetime.datetime.today().date()\n",
    "yesterday = datetime.datetime.today().date()-timedelta(1)\n",
    "\n",
    "def import_district_file(file_location):\n",
    "    district_df = pd.read_csv(file_location)\n",
    "    return district_df\n",
    "\n",
    "def get_district_dict():\n",
    "    district_df = import_district_file('C:/Users/ballinj/housing/london_district_codes.csv')\n",
    "    district_dict = dict(zip(list(district_df['district']), list(district_df['code'])))\n",
    "    return district_dict\n",
    "\n",
    "def get_borough_dict():\n",
    "    df = pd.read_csv('london_borough_list.csv')\n",
    "    borough_dict = dict(zip(list(df['borough']),list(df['code'])))\n",
    "    return borough_dict\n",
    "\n",
    "def get_no_results(soup):\n",
    "    no_results = soup.find('span', attrs={'class':'searchHeader-resultCount'}).text.strip()\n",
    "    return no_results\n",
    "\n",
    "def import_previous_file():\n",
    "    list_of_files = glob.glob('C:/Users/ballinj/housing/data/london/rightmove/*.csv')\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    combined_df_old = pd.read_csv(latest_file, index_col=False)\n",
    "    return combined_df_old\n",
    "\n",
    "def get_individual_soup(url):\n",
    "    cert = \"C:/Users/ballinj/housing/ca-certificates.crt\"\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1667.0 Safari/537.36'}\n",
    "    r = requests.get(url)\n",
    "    c = r.content    \n",
    "    soup = BeautifulSoup(c, 'html.parser')\n",
    "    return(soup)\n",
    "\n",
    "def get_soup(index, region):\n",
    "    district_id = district_dict[region]\n",
    "    cert = \"C:/Users/ballinj/housing/ca-certificates.crt\"\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1667.0 Safari/537.36'}\n",
    "    url = 'https://www.rightmove.co.uk/property-for-sale/find.html'\n",
    "    params = {'minBedrooms':1,\n",
    "              'propertyTypes':'detached%2Cflat%2Csemi-detached%2Cterraced',\n",
    "              'keywords':'',                  \n",
    "              'dontShow':'retirement%2CsharedOwnership',\n",
    "              'channel':'BUY',\n",
    "              'secondaryDisplayPropertyType':'housesandflats',\n",
    "              'index': str(index), \n",
    "              'retirement':'false',\n",
    "              'includeSSTC':'false',\n",
    "              'partBuyPartRent':'false',\n",
    "              'sortType':2,\n",
    "              'minPrice':200000,\n",
    "              'viewType':'list',\n",
    "              'maxPrice':450000,\n",
    "              'radius':0.0,\n",
    "              'locationIdentifier':'OUTCODE%' + str(district_id)[str(district_id).find('%')+1:]}\n",
    "    params_string = \"&\".join(\"%s=%s\" % (k,v) for k,v in params.items())\n",
    "    loaded = False\n",
    "    while not loaded:\n",
    "        r = requests.get(url, params=params_string)\n",
    "        c = r.content    \n",
    "        soup = BeautifulSoup(c, 'html.parser') \n",
    "        if soup.findAll('a', attrs={'class':'propertyCard-anchor'}) != None and soup.find('span', attrs={'class':'searchHeader-resultCount'}) != None:\n",
    "            loaded = True\n",
    "        else:\n",
    "            print('refreshing soup')\n",
    "    return soup\n",
    "\n",
    "def get_json(index, region):\n",
    "    district_id = district_dict[region]\n",
    "    cert = \"C:/Users/ballinj/housing/ca-certificates.crt\"\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1667.0 Safari/537.36'}\n",
    "    url = 'https://www.rightmove.co.uk/property-for-sale/map.html'\n",
    "    params = {'minBedrooms':1,\n",
    "              'propertyTypes':'detached%2Cflat%2Csemi-detached%2Cterraced',\n",
    "              'keywords':'',                  \n",
    "              'dontShow':'retirement%2CsharedOwnership',\n",
    "              'channel':'BUY',\n",
    "              'secondaryDisplayPropertyType':'housesandflats',\n",
    "              'index': str(index), \n",
    "              'retirement':'false',\n",
    "              'includeSSTC':'false',\n",
    "              'partBuyPartRent':'false',\n",
    "              'sortType':2,\n",
    "              'minPrice':200000,\n",
    "              'viewType':'map',\n",
    "              'maxPrice':450000,\n",
    "              'radius':0.0,\n",
    "              'locationIdentifier':'OUTCODE%' + str(district_id)[str(district_id).find('%')+1:]}\n",
    "    params_string = \"&\".join(\"%s=%s\" % (k,v) for k,v in params.items())\n",
    "    loaded = False\n",
    "    while not loaded:\n",
    "        r = requests.get(url, params=params_string)\n",
    "        c = r.content\n",
    "        soup = BeautifulSoup(c, 'html.parser')\n",
    "        scripts = soup.findAll('script')\n",
    "        script_list = [script if 'window.jsonModel' in str(script) else '' for script in scripts]\n",
    "        script_list = [script for script in script_list if script != '']\n",
    "        if len(script_list) != 0:\n",
    "            script = str(script_list[0])\n",
    "            script = script[script.find('{'):script.rfind('}')+1]\n",
    "            properties_json = json.loads(script)\n",
    "            properties_json = properties_json['properties']\n",
    "            loaded = True\n",
    "        else:\n",
    "            print('refreshing json')\n",
    "    print('json retrieved')\n",
    "    return properties_json\n",
    "\n",
    "def get_CR0_json(index):\n",
    "    district_id = district_dict['CR0']\n",
    "    cert = \"C:/Users/ballinj/housing/ca-certificates.crt\"\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1667.0 Safari/537.36'}\n",
    "    url = 'https://www.rightmove.co.uk/property-for-sale/map.html'\n",
    "    viewport_list = ['-0.24224%2C0.0873501%2C51.3716%2C51.4672','-0.240351%2C0.0892384%2C51.282%2C51.3777']\n",
    "    properties_json_list = []\n",
    "    for viewport in viewport_list:\n",
    "        params = {'minBedrooms':1,\n",
    "                  'propertyTypes':'detached%2Cflat%2Csemi-detached%2Cterraced',\n",
    "                  'keywords':'',                  \n",
    "                  'dontShow':'retirement%2CsharedOwnership',\n",
    "                  'channel':'BUY',\n",
    "                  'secondaryDisplayPropertyType':'housesandflats',\n",
    "                  'index': str(0), \n",
    "                  'retirement':'false',\n",
    "                  'includeSSTC':'false',\n",
    "                  'partBuyPartRent':'false',\n",
    "                  'sortType':2,\n",
    "                  'minPrice':200000,\n",
    "                  'viewType':'map',\n",
    "                  'maxPrice':450000,\n",
    "                  'radius':0.0,\n",
    "                  'locationIdentifier':'OUTCODE%' + str(district_id)[str(district_id).find('%')+1:],\n",
    "                  'viewport':viewport}\n",
    "        params_string = \"&\".join(\"%s=%s\" % (k,v) for k,v in params.items())\n",
    "        r = requests.get(url, params=params_string)\n",
    "        c = r.content\n",
    "        soup = BeautifulSoup(c, 'html.parser')\n",
    "        scripts = soup.findAll('script')\n",
    "        script_list = [script if 'window.jsonModel' in str(script) else '' for script in scripts]\n",
    "        script_list = [script for script in script_list if script != '']\n",
    "        script = str(script_list[0])\n",
    "        script = script[script.find('{'):script.rfind('}')+1]\n",
    "        properties_json = json.loads(script)\n",
    "        properties_json = properties_json['properties']\n",
    "        for p in properties_json:\n",
    "            if str(p['id']) not in [str(property['id']) for property in properties_json_list]:\n",
    "                properties_json_list.append(p)\n",
    "    return properties_json_list\n",
    "\n",
    "def format_data_soup(soup, region):\n",
    "    no_results = get_no_results(soup)\n",
    "    print(no_results + ' results found')\n",
    "    print('obtaining soup...')\n",
    "    index_array = np.arange(0,int(no_results)+24,24).tolist()\n",
    "    listing_ids, links, property_types, addresses, prices, featured_properties = [],[],[],[],[],[]\n",
    "    added_reduced_array, letting_agent_name, letting_agent_number, num_pictures = [],[],[],[]\n",
    "    for index in index_array:\n",
    "        soup = get_soup(index, region)\n",
    "        time.sleep(0.5)\n",
    "        main_data = soup.find('div', attrs={'class':'main'})\n",
    "        search_results = soup.find('div', attrs={'class':'l-searchResults'})\n",
    "        ids = soup.findAll('a', attrs={'class':'propertyCard-anchor'})#['id']\n",
    "        for id in ids:\n",
    "            listing_ids.append(id['id'][4:])\n",
    "        listing_data = search_results.findAll('div', attrs={'class':'propertyCard-wrapper'})\n",
    "        for listing in listing_data:\n",
    "            featured_properties.append(listing.find('div', attrs={'class':'propertyCard-moreInfoFeaturedTitle'}).text.strip())\n",
    "\n",
    "            details = listing.find('div', attrs={'class':'propertyCard-details'})\n",
    "            addresses.append(listing.find('address').text.strip())\n",
    "            property_types.append(listing.find('h2').text.strip())\n",
    "            links.append('https://www.rightmove.co.uk' + details.find('a')['href'])\n",
    "\n",
    "            pricing = listing.find('div', attrs={'class':'propertyCard-price'})\n",
    "            prices.append(pricing.find('div', attrs={'class':'propertyCard-priceValue'}).text.strip())\n",
    "            added_reduced_array.append(listing.find('div', attrs={'class':'propertyCard-branchSummary'}).find('span', attrs={'class':'propertyCard-branchSummary-addedOrReduced'}).text.strip())\n",
    "            estate_agent = listing.find('div', attrs={'class':'propertyCard-branchSummary'}).find('span', attrs={'class':'propertyCard-branchSummary-branchName'}).text.strip()\n",
    "            estate_agent = estate_agent[estate_agent.find('by')+3:].strip()\n",
    "            letting_agent_name.append(estate_agent)\n",
    "            letting_agent_number.append(listing.find('div', attrs={'class':'propertyCard-contacts'}).find('a', attrs={'class':'propertyCard-contactsPhoneNumber'}).text.strip())\n",
    "            meta_data = listing.find('div', attrs={'class':'propertyCard-moreInfoMeta'})\n",
    "            num_pictures.append(meta_data.find('span', attrs={'class':'propertyCard-moreInfoNumber'}).text.strip())\n",
    "    listing_df = pd.DataFrame(listing_ids, columns=['listing_id'])\n",
    "    listing_df['address'] = addresses\n",
    "    listing_df['property_type'] = property_types\n",
    "    listing_df['property_link'] = links\n",
    "    listing_df['price'] = prices\n",
    "    listing_df['added/reduced_date'] = added_reduced_array\n",
    "    listing_df['agent_name'] = letting_agent_name\n",
    "    listing_df['agent_number'] = letting_agent_number\n",
    "    listing_df['no_pictures'] = num_pictures\n",
    "    listing_df['featured_property'] = featured_properties\n",
    "    listing_df = listing_df[~listing_df['property_type'].str.contains('share')]\n",
    "    listing_df = listing_df[~listing_df['property_type'].str.contains('Parking')]\n",
    "    listing_df = listing_df[listing_df['address']!=\"\"]\n",
    "    listing_df = listing_df[listing_df['featured_property']==\"\"]\n",
    "    listing_df = listing_df.reset_index(drop=True)\n",
    "    return listing_df\n",
    "\n",
    "def format_missed_data(housing_soup_data, properties_json_list):\n",
    "    soup_list = housing_soup_data['listing_id'].tolist()\n",
    "    json_list = list(properties_json_list)\n",
    "    missed_ids, missed_links = [],[]\n",
    "    for item in json_list:\n",
    "        if item not in soup_list:\n",
    "            missed_ids.append(item)\n",
    "    missed_links = ['https://www.rightmove.co.uk/property-for-sale/property-' + str(item) + '.html' for item in missed_ids]\n",
    "    listing_ids, links, property_types, addresses, prices, featured_properties = [],[],[],[],[],[]\n",
    "    added_reduced_array, letting_agent_name, letting_agent_number, num_pictures = [],[],[],[]\n",
    "\n",
    "    for id,link in list(zip(missed_ids,missed_links))[:10]:\n",
    "        listing_ids.append(id)\n",
    "        links.append(link)\n",
    "        soup = get_individual_soup(link)\n",
    "        listing_details = soup.find('div', attrs={'id':'primaryContent'})\n",
    "        property_types.append(listing_details.find('h1', attrs={'class':'fs-22'}).text.strip())\n",
    "        addresses.append(listing_details.find('address', attrs={'itemprop':'address'}).text.strip())\n",
    "        prices.append(listing_details.find('p', attrs={'id':'propertyHeaderPrice'}).text.strip())\n",
    "        try:\n",
    "            added_reduced = soup.find('div', attrs={'id':'firstListedDate'}).text.strip().replace(' Rightmove:','') + ' '\n",
    "            added_reduced = added_reduced + datetime.datetime.strptime(soup.find('div', attrs={'id':'firstListedDateValue'}).text.strip(), '%d %B %Y').strftime('%d/%m/%Y')\n",
    "            added_reduced_array.append(added_reduced)\n",
    "        except AttributeError:\n",
    "            added_reduced_array.append(None)\n",
    "        letting_agent_name.append(soup.find('a', attrs={'id':'aboutBranchLink'}).text.strip())\n",
    "        letting_agent_number.append(soup.find('div', attrs={'id':'requestdetails'}).contents[4].contents[1].text.strip())\n",
    "        num_pictures.append(soup.find('span', attrs={'class':'gallery-main-status'}).text.strip()[-2:].strip())\n",
    "        time.sleep(1)\n",
    "    listing_df = pd.DataFrame(listing_ids, columns=['listing_id'])\n",
    "    listing_df['address'] = addresses\n",
    "    listing_df['property_type'] = property_types\n",
    "    listing_df['property_link'] = links\n",
    "    listing_df['price'] = prices\n",
    "    listing_df['added/reduced_date'] = added_reduced_array\n",
    "    listing_df['agent_name'] = letting_agent_name\n",
    "    listing_df['agent_number'] = letting_agent_number\n",
    "    listing_df['no_pictures'] = num_pictures\n",
    "    listing_df['featured_property'] = ''\n",
    "    listing_df = listing_df[~listing_df['property_type'].str.contains('share')]\n",
    "    listing_df = listing_df[~listing_df['property_type'].str.contains('Parking')]\n",
    "    listing_df = listing_df[listing_df['address']!=\"\"]\n",
    "    listing_df = listing_df.reset_index(drop=True)\n",
    "    housing_soup_data = pd.concat([housing_soup_data,listing_df], ignore_index=True)\n",
    "    return housing_soup_data\n",
    "    \n",
    "\n",
    "def format_data_json(properties_json):\n",
    "    property_id, coordinates = [],[]\n",
    "    for row in properties_json:\n",
    "        property_id.append(str(row['id']))\n",
    "        coordinates.append([row['location']['latitude'], row['location']['longitude']])\n",
    "    coordinates_dict = dict(zip(property_id, coordinates))\n",
    "    print('json formatted')\n",
    "    return coordinates_dict\n",
    "\n",
    "def housing_data_merge(housing_soup_data, housing_json_data):\n",
    "    latitudes, longitudes = [],[]\n",
    "    housing_soup_data = housing_soup_data[housing_soup_data['listing_id'].isin(list(housing_json_data.keys()))]\n",
    "    for id in housing_soup_data['listing_id'].tolist():\n",
    "        latitudes.append(housing_json_data[str(id)][0])\n",
    "        longitudes.append(housing_json_data[str(id)][1])\n",
    "    housing_soup_data['latitude'] = latitudes\n",
    "    housing_soup_data['longitude'] = longitudes\n",
    "    return housing_soup_data\n",
    "\n",
    "def format_housing_data_total(housing_data_total):\n",
    "    print(datetime.datetime.strftime(datetime.datetime.today(),'%H:%M:%S') + ' - formatting data')\n",
    "    price_list = [price.replace('£','').replace(',','') for price in housing_data_total['price'].tolist()]\n",
    "    housing_data_total.drop(columns=['price'])\n",
    "    housing_data_total['price'] = price_list\n",
    "    housing_data_total['most_recent_scrape_date'] = datetime.datetime.today().date()\n",
    "    room_df = pd.DataFrame(housing_data_total['property_type'].str.split(' bedroom ',1).tolist(),\n",
    "                                       columns = ['no_rooms','property_type'])\n",
    "    housing_data_total['added/reduced_date'] = housing_data_total['added/reduced_date'].fillna('unknown')\n",
    "    added_reduced_list = [ele.replace(' yesterday',' on ' + str(yesterday)).replace(' today',' on ' + str(today)) for ele in housing_data_total['added/reduced_date'].tolist()]\n",
    "    housing_data_total = housing_data_total.drop(columns=['added/reduced_date'])\n",
    "    housing_data_total['added/reduced_date'] = added_reduced_list\n",
    "    reduced_df = pd.DataFrame(housing_data_total['added/reduced_date'].str.split(' on ',1).tolist(),\n",
    "                                       columns = ['added/reduced','added/reduced_date'])\n",
    "    reduced_df['added/reduced_date'] = reduced_df['added/reduced_date'].fillna('unknown')\n",
    "    housing_data_total = housing_data_total.drop(columns=['property_type','added/reduced_date'])\n",
    "    housing_data_total = pd.concat([housing_data_total,room_df], axis=1)\n",
    "    housing_data_total = pd.concat([housing_data_total,reduced_df], axis=1)\n",
    "    housing_data_total['property_type'] = housing_data_total['property_type'].str.replace(' for sale','')\n",
    "    housing_data_total_old = import_previous_file()\n",
    "    initial_scrape_date = []\n",
    "    for index, row in housing_data_total.iterrows():\n",
    "        if int(row['listing_id']) not in housing_data_total_old['listing_id'].tolist():\n",
    "            initial_scrape_date.append(str(datetime.datetime.today().date()))\n",
    "        else:\n",
    "            required_date = housing_data_total_old[housing_data_total_old['listing_id']==int(row['listing_id'])]['initial_scrape_date'].tolist()[0]\n",
    "            initial_scrape_date.append(required_date)\n",
    "    housing_data_total['initial_scrape_date'] = initial_scrape_date\n",
    "    housing_data_total = housing_data_total[['listing_id',\n",
    "                                             'district',\n",
    "                                             'address',\n",
    "                                             'price',\n",
    "                                             'no_rooms',\n",
    "                                             'property_type',\n",
    "                                             'property_link',\n",
    "                                             'added/reduced',\n",
    "                                             'added/reduced_date',\n",
    "                                             'initial_scrape_date',\n",
    "                                             'most_recent_scrape_date',\n",
    "                                             'no_pictures',\n",
    "                                             'latitude',\n",
    "                                             'longitude',\n",
    "                                             'agent_name',\n",
    "                                             'agent_number']]\n",
    "    for index, row in housing_data_total_old.iterrows():\n",
    "        if int(row['listing_id']) not in [int(id) for id in housing_data_total['listing_id'].tolist()]:\n",
    "            housing_data_total = housing_data_total.append(row)\n",
    "    housing_data_total['added/reduced_date'] = housing_data_total['added/reduced_date'].apply(lambda x:datetime.datetime.strptime(str(x), '%d/%m/%Y') if '/' in str(x) else (datetime.datetime.strptime(str(x),'%Y-%m-%d') if '-' in str(x) else None))\n",
    "    housing_data_total['initial_scrape_date'] = housing_data_total['initial_scrape_date'].apply(lambda x:datetime.datetime.strptime(str(x), '%d/%m/%Y') if '/' in str(x) else (datetime.datetime.strptime(str(x),'%Y-%m-%d') if '-' in str(x) else None))\n",
    "    housing_data_total['most_recent_scrape_date'] = housing_data_total['most_recent_scrape_date'].apply(lambda x:datetime.datetime.strptime(str(x), '%d/%m/%Y') if '/' in str(x) else (datetime.datetime.strptime(str(x),'%Y-%m-%d') if '-' in str(x) else None))\n",
    "    housing_data_total = housing_data_total[~housing_data_total['property_link'].str.contains('commercial-property')]\n",
    "    housing_data_total = housing_data_total[housing_data_total['no_rooms'] != 'Hotel room for sale']\n",
    "    housing_data_total = housing_data_total.reset_index(drop=True)\n",
    "    print('data formatted')\n",
    "    return housing_data_total\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 3956 # Radius of earth in kilometers = 6371. Use 3956 for miles\n",
    "    return c * r\n",
    "\n",
    "def add_stations(df):\n",
    "    print(datetime.datetime.strftime(datetime.datetime.today(),'%H:%M:%S') + ' - adding stations')\n",
    "    tube_stations = pd.read_csv('C:/Users/ballinj/housing/london_stations.csv', sep=',', index_col='FID')\n",
    "    distance_list,ids = [],[]\n",
    "    for id,lat, long in list(zip(df['listing_id'].tolist(),df['latitude'].tolist(),df['longitude'].tolist())):\n",
    "        distance_temp, distance_from_station_temp = [],[]\n",
    "        for index, row in tube_stations.iterrows():\n",
    "            distance_temp.append(haversine(long, lat, row['x'], row['y']))\n",
    "            distance_from_station_temp.append(row['NAME'])\n",
    "        zipped = zip(distance_temp,distance_from_station_temp)\n",
    "        distance_list.append(list(sorted(zipped, key=lambda x: x[0])[:3]))\n",
    "        ids.append(id)\n",
    "    distance_dict = dict(zip(ids,distance_list))\n",
    "    station_a_dist, station_b_dist, station_c_dist = [],[],[]\n",
    "    station_a, station_b, station_c = [],[],[]\n",
    "    for listing_id in df['listing_id'].tolist():\n",
    "        station_a_dist.append(distance_dict[listing_id][0][0])\n",
    "        station_b_dist.append(distance_dict[listing_id][1][0])\n",
    "        station_c_dist.append(distance_dict[listing_id][2][0])\n",
    "        station_a.append(distance_dict[listing_id][0][1])\n",
    "        station_b.append(distance_dict[listing_id][1][1])\n",
    "        station_c.append(distance_dict[listing_id][2][1])\n",
    "    df['closest_station'] = station_a\n",
    "    df['closest_station_dist (miles)'] = station_a_dist\n",
    "    df['second_closest_station'] = station_b\n",
    "    df['second_closest_station_dist (miles)'] = station_b_dist\n",
    "    df['third_closest_station'] = station_c\n",
    "    df['third_closest_station_dist (miles)'] = station_c_dist\n",
    "    print('stations added')\n",
    "    return df\n",
    "\n",
    "def add_pubs_score(housing_df):\n",
    "    \n",
    "    def format_total_normalised(row):\n",
    "        if row['quantity'] == 0:\n",
    "            return df['total_normalised'].min() - 0.01\n",
    "        else:\n",
    "            return row['total_normalised']\n",
    "    \n",
    "    print(datetime.datetime.strftime(datetime.datetime.today(),'%H:%M:%S') + ' - adding pubs')\n",
    "    relevant_pubs = pd.read_csv('C:/Users/ballinj/housing/pubs_data.csv', index_col=0)\n",
    "    relevant_pubs['rating'] = relevant_pubs['rating'].replace('unknown',0)\n",
    "    relevant_pubs['rating'] = pd.to_numeric(relevant_pubs['rating'])\n",
    "    relevant_pubs['rating'] = relevant_pubs['rating'].replace(0,relevant_pubs[relevant_pubs['rating']!=0]['rating'].mean())\n",
    "    property_pub_proximity_ratings, property_pub_average_ratings, property_pub_nos = [],[],[]\n",
    "    for lat, long in list(zip(housing_df['latitude'],housing_df['longitude'])):\n",
    "        pub_distances = []\n",
    "        for index, row in relevant_pubs.iterrows():\n",
    "            pub_distances.append(haversine(long, lat,row['long'],row['lat']))\n",
    "        pub_details = list(zip(pub_distances, relevant_pubs['rating'].tolist()))\n",
    "        near_pub_details = [row for row in pub_details if row[0] < 1]\n",
    "        if len(near_pub_details) > 0:\n",
    "            near_pub_average_rating = sum([row[1] for row in near_pub_details])/len(near_pub_details)\n",
    "            near_pub_proximity_rating = sum([row[0] for row in near_pub_details])/len(near_pub_details)\n",
    "        else:\n",
    "            near_pub_proximity_rating = 0\n",
    "            near_pub_average_rating = 0\n",
    "        property_pub_proximity_ratings.append(near_pub_proximity_rating)\n",
    "        property_pub_average_ratings.append(near_pub_average_rating)\n",
    "        property_pub_nos.append(len(near_pub_details))\n",
    "\n",
    "    list_df = list(zip(housing_df['listing_id'], property_pub_proximity_ratings, property_pub_nos, property_pub_average_ratings))\n",
    "    df = pd.DataFrame(list_df, columns=['listing_id','proximity','quantity','quality'])\n",
    "    df['proximity_normalised'] = df['proximity']-0.3 # here we presume that 300m is the optimal distance away from a pub\n",
    "    df['proximity_normalised'] = df['proximity_normalised'].abs() # here we penalised houses that are within 300m of a pub by taking the modulus\n",
    "    df['proximity_normalised'] = (df['proximity_normalised'] - df['proximity_normalised'].min())/(df['proximity_normalised'] - df['proximity_normalised'].min()).max()\n",
    "    df['quantity_normalised'] = df['quantity']/df['quantity'].max()\n",
    "    df['quality_normalised'] = (df['quality']-df[df['quality']!=0]['quality'].min())/(df['quality']-df[df['quality']!=0]['quality'].min()).max()\n",
    "    df['quality_normalised'][df['quality_normalised']<0] = 0\n",
    "    df['total_normalised'] = 0.5*df['quantity_normalised'] + 2*df['quality_normalised'] - df['proximity_normalised']\n",
    "    df['total_normalised'] = df.apply(lambda row: format_total_normalised(row), axis=1)\n",
    "    df['total_rank'] = df['total_normalised'].rank(ascending=False)\n",
    "    housing_df = pd.concat([housing_df,df], axis=1)\n",
    "    return housing_df\n",
    "print('functions loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:13:26.216589\n",
      "BR1\n",
      "196 results found\n",
      "obtaining soup...\n",
      "json retrieved\n",
      "json formatted\n",
      "BR1 complete\n",
      "1 out of 298\n",
      "\n",
      "\n",
      "BR2\n",
      "178 results found\n",
      "obtaining soup...\n",
      "json retrieved\n",
      "json formatted\n",
      "BR2 complete\n",
      "2 out of 298\n",
      "\n",
      "\n",
      "BR3\n",
      "113 results found\n",
      "obtaining soup...\n",
      "json retrieved\n",
      "json formatted\n",
      "BR3 complete\n",
      "3 out of 298\n",
      "\n",
      "\n",
      "15:14:16 - formatting data\n",
      "data formatted\n",
      "15:14:17 - adding stations\n",
      "stations added\n",
      "15:14:34 - adding pubs\n",
      "PROCESS COMPLETE\n",
      "15:15:26.419731\n",
      "time taken: 0:02:00.203142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ballinj\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:403: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "start_time = str(datetime.datetime.now().time()) \n",
    "print(start_time)\n",
    "district_dict = get_district_dict()\n",
    "district_list = import_district_file('C:/Users/ballinj/housing/london_district_codes.csv')['district'].tolist()\n",
    "housing_data_total = pd.DataFrame()\n",
    "i = 1\n",
    "for district in district_list:\n",
    "    print(district)\n",
    "    housing_soup = get_soup(index=0, region=district)\n",
    "    housing_soup_data = format_data_soup(housing_soup, region=district)\n",
    "    if district != 'CR0':\n",
    "        housing_json = get_json(index=0, region=district)\n",
    "        housing_json_data = format_data_json(housing_json)\n",
    "    else:\n",
    "        housing_json = get_CR0_json(index=0)\n",
    "        housing_json_data = format_data_json(housing_json)\n",
    "        housing_soup_data = format_missed_data(housing_soup_data, housing_json_data)\n",
    "    housing_data_merge_df = housing_data_merge(housing_soup_data, housing_json_data)\n",
    "    housing_data_merge_df['district'] = district\n",
    "    housing_data_total = pd.concat([housing_data_total,housing_data_merge_df], ignore_index=True)\n",
    "    time.sleep(3)\n",
    "    print(district + ' complete')\n",
    "    print(str(i) + ' out of ' + str(len(district_list)))\n",
    "    print('\\n')\n",
    "    i += 1\n",
    "housing_data_total_formatted = format_housing_data_total(housing_data_total)\n",
    "housing_data_total_stations = add_stations(housing_data_total_formatted)\n",
    "housing_data_total_pubs = add_pubs_score(housing_data_total_stations)\n",
    "housing_data_total_stations.to_csv('data/london/rightmove/properties_by_district_{}.csv'.format(str(today)), index=False)\n",
    "print('PROCESS COMPLETE')\n",
    "end_time = str(datetime.datetime.now().time()) \n",
    "print(end_time)\n",
    "time_taken = datetime.datetime.strptime(end_time, '%H:%M:%S.%f') - datetime.datetime.strptime(start_time, '%H:%M:%S.%f')\n",
    "time_taken = str(time_taken)\n",
    "print('time taken: ' + time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>no_rooms</th>\n",
       "      <th>no_pictures</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.840700e+04</td>\n",
       "      <td>28407.000000</td>\n",
       "      <td>28407.000000</td>\n",
       "      <td>28407.000000</td>\n",
       "      <td>28407.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.788744e+07</td>\n",
       "      <td>2.002992</td>\n",
       "      <td>9.821241</td>\n",
       "      <td>51.491506</td>\n",
       "      <td>-0.112505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.321040e+06</td>\n",
       "      <td>0.806375</td>\n",
       "      <td>4.069904</td>\n",
       "      <td>0.623702</td>\n",
       "      <td>1.467051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.279557e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-35.280937</td>\n",
       "      <td>-103.853291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.001381e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>51.426493</td>\n",
       "      <td>-0.246036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.898936e+07</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>51.500380</td>\n",
       "      <td>-0.093610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.620633e+07</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>51.565348</td>\n",
       "      <td>0.014083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.007021e+07</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>149.130004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         listing_id      no_rooms   no_pictures      latitude     longitude\n",
       "count  2.840700e+04  28407.000000  28407.000000  28407.000000  28407.000000\n",
       "mean   6.788744e+07      2.002992      9.821241     51.491506     -0.112505\n",
       "std    8.321040e+06      0.806375      4.069904      0.623702      1.467051\n",
       "min    3.279557e+07      1.000000      0.000000    -35.280937   -103.853291\n",
       "25%    6.001381e+07      1.000000      7.000000     51.426493     -0.246036\n",
       "50%    6.898936e+07      2.000000      9.000000     51.500380     -0.093610\n",
       "75%    7.620633e+07      3.000000     12.000000     51.565348      0.014083\n",
       "max    8.007021e+07      7.000000     86.000000     54.000000    149.130004"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/ballinj/housing/data/london/rightmove/properties_by_district_2019-03-11.csv')\n",
    "df[df.columns[:16]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
